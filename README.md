# Multi-modal-language-model

Multimodal LLMs are capable of processing and understanding data from multiple sources â€” such as text, images, and audio. This notebook introduces:

- The fundamentals of **multimodal models**
- How to integrate **vision transformers (ViTs)** with language models
- Examples of using **image and text inputs together**
- How to build and test multimodal pipelines with **pretrained models**
  
Colab : https://colab.research.google.com/drive/1IJ2cON-Q4UTTEqpVPGVt52CZg0GXeExB#scrollTo=NMF9p8qK58Ou

Youtube : https://youtu.be/f8tIKzEOA1o
